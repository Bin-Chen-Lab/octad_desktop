---
title: "breast cancer LumA example"
output:
  html_document:
    toc: true
    theme: united
---

Note: Total time of this pipeline is largely dependent on whether several "optional" blocks are enabled. With all optional blocks disabled, it usually runs 15-20min. With all optional blocks enabled, it can take over an hour. The optional blocks are marked with #optional and estimated time required.


```{r setup, include=TRUE, echo=TRUE, message=FALSE, warning=FALSE}
start.time <- Sys.time()
# knitr::opts_knit$set(root.dir = '../..')
base.folder <- '/Users/newburyp/Documents/Chen Lab/Projects/desktop_pipeline/desktop_pipeline_condensed/' # should be set to installation parent folder
setwd(base.folder)
library(dplyr)
library(ggplot2)
library("RUVSeq")
library("GSVA")
library(compiler)
library(data.table)
library(devtools)
library(limma)
# library(doParallel)


enableJIT(3)


iteration = 1 # don't touch this. Below automatically increases "iteration" upon detection of previous runs.
for (i in 1:length(dir(normalizePath('./results/')))) {
if (dir.exists(paste0(normalizePath(paste0('./results/results_',Sys.Date(),'_',i,'/')),'/'))==TRUE) 
  iteration = iteration + 1
}

outputFolder = paste0(normalizePath(paste0('./results/results_',Sys.Date(),'_',iteration,'/')),'/')
if (!dir.exists(outputFolder)) {
  dir.create(outputFolder)
}
outputFolder = paste0(normalizePath(paste0('./results/results_',Sys.Date(),'_',iteration,'/')),'/')
dataFolder = paste0(normalizePath('./data/'),'/')
CodeFolder = paste0(normalizePath('./code/'),'/')
dataFolder
CodeFolder

load(paste0(dataFolder,'metadata.RData')) # loads 'ensemble_info', 'merged_gene_info', 'breastpam50', 'tsne', and 'phenoDF'

source(paste0(CodeFolder,'core_functions.R'))

# avoiding logging errors
tsne.time    <- "Not run"
GEA.time     <- "Not run"
VDH.time     <- "Not run"
enrich.time  <- "Not run"
ranking.time <- "Not run"
```

Here, you will normalize samples for batch effects with package "RUVSeq". You can set it off by changing set parameters script.   
Set parameters. Below are default settings. 
You can set normalize_samples = F to make it run faster at risk of batch effects.  
```{r parameters}
setwd(base.folder)
# DE params:
normalize_samples = T
k = 1
n_topGenes = 10000
#this demo sample set does not have too much genes. The usual default for n_topGenes = 10000. Set this higher if you think there are more significant genes
DE_method = 'edgeR' # Other choice is 'limma' for DE_method.


# disease signature params:
log2fchange <- 2 # the cutoff for "significant gene impact". Default = 1, so any DE gene with log2foldchange < 1 will be omitted. Improved results with 2.
padjusted <- 0.001 # the cutoff for "significant genes". Default = 0.001, so any DE genes with padj > 0.001 will be omitted.


# sRGES params:
# Only mess with "max_gene_size", which is how many up-regulated genes and down-regulated genes are allowed. ("100" = 100up + 100down = 200 total)
landmark = 1
choose_fda_drugs = F
max_gene_size = 100
weight_cell_line = F

# logging parameters
write('x', file = paste0(outputFolder,"parameters.txt"))
fileConn<-file(paste0(outputFolder,"parameters.txt"))
writeLines(c("Normalization Parameters:","normalize_samples",normalize_samples,"","k",k,"","n_topGenes",n_topGenes,"","DE_method",DE_method,"","--------------------------","","Disease Signature Parameters:","log2fchange",log2fchange,"","padjusted",padjusted,"","--------------------------","","sRGES Parameters:","landmark",landmark,"","choose_fda_drugs",choose_fda_drugs,"","max_gene_size",max_gene_size,"","weight_cell_line",weight_cell_line), fileConn)
close(fileConn)

```

Have the following files in your dataFolder:

* metadata.RData  
* dz.expr.log2.readCounts.RData [expression data]    
* cmpd_sets_chembl_targets.RData  
* cmpd_sets_mesh.RData  
* cmpd_sets_meshes.RData  
* cmpd_sets_sea_targets.RData  
* cmpd_sets_ChemCluster.RData
* encoderDF_AEmodel1.RData  
* lincs_sig_info.csv  
* lincs_signatures_cmpd_landmark_symbol.RData  
* CCLE_OCTAD.RData  
* repurposing_drugs_20170327.csv  
* metadata.RData  

```{r dataFolder, results='hide'}
setwd(base.folder)
dir(dataFolder)
#check to make sure you have these files
```
***

Have the following scripts in your CodeFolder:  
  
* [your workflow].Rmd (this Rmd is an example)  
* core_functions.R  
* Diff_Exp.R  
* drug_enrichment_analysis.R  
* gene_enrichment_analysis.R  
* RankCellLines.R  
* runRGES_dz_arrangeMax.R (or runRGES_dz_arrangeMax_compiler.R or runRGES_dz_arrangeMax_doParallel.R)  
* visualize_drug_hits.R  
```{r CodeFolder}
setwd(base.folder)
dir(CodeFolder)
#check to make sure you have these files
```
***

Load the dataframes that contain your case and normal reference tissues.  
DO NOT VIEW these dataframes. They're too large. Use the colnames, rownames, and dim functions. Otherwise, you may crash.
```{r data.load}
setwd(base.folder)
data.load.start <- Sys.time()
load(paste0(dataFolder,'dz.expr.log2.readCounts.RData'))
load(paste0(dataFolder,'encoderDF_AEmodel1.RData')) # only need to load this if you are using EncoderDF.
#File dz.expr.log2.readCounts.RData will give you mRNA counts. 
#the expression dataframe table is called dz.expr.log2.read.count

#the phenotype dataframe is called phenoDF, loaded earlier via metadata.RData

data.load.end  <- Sys.time()
data.load.time <- data.load.end - data.load.start
data.load.time
```
***

##Select Cases##    
```{r case.load1}
setwd(base.folder)
case.load.start <- Sys.time()

lumA_over50    <- breastpam50 %>% filter(LumA > 0.5)
phenoDF_case   <- phenoDF %>% filter(cancer == 'Breast Invasive Carcinoma', sample.type != 'adjacent', data.source == 'TCGA', gender == 'Female')
allbrcaids     <- phenoDF_case$sample.id
lumA_onlydz    <- lumA_over50 %>% filter(sample.id %in% allbrcaids)
phenoDF_case   <- filter(phenoDF,sample.id %in% as.character(lumA_onlydz$sample.id))

# skin sample example
# condinfo     <- grep('^SKIN',phenoDF$biopsy.site)
# skin.samples <- phenoDF$sample.id[condinfo]
# tcgaskinids  <- (phenoDF %>% filter(cancer == 'Skin Cutaneous Melanoma'))$sample.id
# gtexskinids  <- (phenoDF %>% filter(cancer == 'normal',sample.id %in% skin.samples))$sample.id
# all.samples  <- c(unlist(tcgaskinids), unlist(gtexskinids))
# phenoDF_skin <- phenoDF[phenoDF$sample.id %in% all.samples,]
# phenoDF_case <- phenoDF_skin %>% 
#   filter(cancer == 'Skin Cutaneous Melanoma',
#          sample.type %in% c('metastatic'))
# case.cancer <- c('Cutaneous Melanoma','Head And Neck Mucosal Melanoma','Skin Cutaneous Melanoma')
# phenoDF_case <- phenoDF %>% 
#   filter(cancer %in% case.cancer,
#          sample.type %in% c('metastatic'))

```
***  

Create a list with sample IDs for the cancer of interest (case). 
```{r case.load2}
case_id <- phenoDF_case$sample.id
```
Results: **`r nrow(phenoDF_case)`** case IDs.  
***

##Select Reference Control Samples##  
***
Identify the sample.id of normal tissues in the phenoDF. They should be from the GTEX database and contain "GTEX..." in the start of the sample ID name.
```{r case.load3}
setwd(base.folder)
phenoDF_Female <- phenoDF %>% filter(gender == "Female")
normal_id = (phenoDF_Female %>% filter(data.source == 'GTEX'))$sample.id

# normal_id = (phenoDF_skin %>% filter(data.source == 'GTEX'))$sample.id
# all.mitf <- subset(df,rownames(df) %in% all.samples)
# all.mitf.pheno <- merge(x=all.mitf,y=phenoDF[,c('sample.id','sample.type','biopsy.site')],by.x="row.names",by.y="sample.id", allx=TRUE)


# if including adjacents:
# normal_id = c(normal_id,(phenoDF %>% filter(sample.type == 'adjacent'))$sample.id)

```
***


Define normal and case counts. Combine the normal and case counts by generating a table called dz_expr containing columns of normal and case sample IDs vs rows of genes. 
```{r case.load4}
setwd(base.folder)
# normal_counts = dz.expr.log2.read.count[,normal_id]  
# case_counts = dz.expr.log2.read.count[,case_id]

normal_counts = EncoderDF[,normal_id]
case_counts = EncoderDF[,case_id]

(row.names(case_counts) == row.names(normal_counts)) %>% sum() # should be 64
#quick check to see that all genes match up before combining  

dz_expr = cbind(normal_counts, case_counts)

rm(normal_counts, case_counts) # free up some memory

dim(dz_expr)
```
Results: **`r nrow(dz_expr)`** rows of genes vs **`r ncol(dz_expr)`** total columns of combined **`r nrow(phenoDF %>% filter(data.source == 'GTEX'))`** normal and **`r nrow(phenoDF_case)`** case samples  

***

Define your control ID--the control samples you are comparing your case with. The computeRefTussue function will match similar normal samples to your chosen cancer.  This function is based on mRNA data of high varying expression across all tissues.  
You will generate **50** control samples, unless you state a different control_size.
```{r case.load6}
setwd(base.folder)

control_id <- computeRefTissue(case_id = case_id, #computes ref tissue given case_id, normal_id chr vectors
                               normal_id = normal_id,
                               expSet = dz_expr, #expSet is a counts dataframe that contains both case and normal counts. 
                               control_size = 50) 
head(control_id)
#this function will also generate a csv called case_normal_median_cor.csv that includes the median correlation of each normal sample.
normal_counts = dz.expr.log2.read.count[,control_id]
case_counts = dz.expr.log2.read.count[,case_id]
dz_expr = cbind(normal_counts, case_counts)
rm(normal_counts) # free up some memory

case.load.end <- Sys.time()

case.load.time <- case.load.end - case.load.start
case.load.time
```
***

Check the tissue location of where the control samples are from.
```{r verify1}
setwd(base.folder)
(phenoDF %>% filter(sample.id %in% control_id) %>% select(biopsy.site) %>% table())
```
If I want, I can exclude certain samples.
***

##Visualization of Case Vs. Reference Samples##  
***

To see how similar the controls are to the case samples, get the correlations of mRNA expressions between each of the normal samples and the set of cases. The list is in descending order.
```{r verify2}
setwd(base.folder)
normal_median_cor = read.csv(paste0(outputFolder,'case_normal_median_cor.csv'),stringsAsFactors = F)
normal_median_cor <- normal_median_cor %>% arrange(desc(cor))

normal_median_cor <-left_join(normal_median_cor, 
  phenoDF %>% select(sample.id, biopsy.site), 
  by = "sample.id")

head(normal_median_cor)
```
***

Goal is to sort the correlation order based on tissue type.  
***

I) Find median correlation for each primary site
```{r verify3}
setwd(base.folder)
(reference_tissue_rank <- normal_median_cor %>% 
  group_by(biopsy.site) %>% summarise(medianCor = median(cor)) %>% 
  ungroup())
```

II) Sort the median correlation of the different tissues from high to low
```{r verify4}
setwd(base.folder)
(top_refs = reference_tissue_rank %>% arrange(desc(medianCor)))
#top_refs <-  reference_tissue_rank[1:10, 1]
```

III) Sort tissue from high to low correlation. Top ten shown.
```{r verify5}
setwd(base.folder)
normal_median_cor$ref <- factor(normal_median_cor$biopsy.site, levels = top_refs$biopsy.site)
levels(normal_median_cor$ref)[1:10]
```

IV) Graph tissue type vs mRNA correlation
```{r fig1, fig.height=9, fig.align= "center"}
setwd(base.folder)

p <- ggplot(normal_median_cor, aes(ref, cor))
p +   geom_boxplot(color='grey', notch=F, outlier.shape = NA) + 
  geom_jitter(aes(alpha=1/100), show.legend = F) + 
  theme_bw() + 
  ylab("correlation") + 
  xlab("") + 
  labs (title='Correlation between Case Samples and Reference Tissue',caption='OCTAD')+
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 11),
  axis.text.y = element_text(size = 11), axis.title = element_text(size = 11), 
  plot.margin = margin(l=0))

ggsave('correlation graph.pdf', paper='a4r', path=outputFolder)
```

##Visualize on Cancer Map##
Optional case-control visualization.
```{r cancermap, fig.height=10, fig.align= "center"}
#optional - duration: approximately 3 seconds
setwd(base.folder)

tsne.time.start <- Sys.time()

#make a new column called type to state case, control, or others
tsne$type <- "others"
tsne$type[tsne$sample.id %in% case_id] <- "case"
tsne$type[tsne$sample.id %in% control_id] <- "control"

#plot 
(p2 <- ggplot(tsne, aes(X, Y, color = type)) + geom_point(alpha = 0.4)+
    labs(title = paste ('TNSE PLOT'), x= 'TSNE Dim1', y='TSNE Dim2', caption="OCTAD"))

ggsave("case_control_map.pdf", path=outputFolder)

tsne.time.stop <- Sys.time()
tsne.time <- tsne.time.stop - tsne.time.start
tsne.time
```

##Optional: Selecting Another Set of Reference Samples##  
***
```{r referencesample2}
setwd(base.folder)
#optional
#2a. select normals based on the top site computed e.g. if brain was top site select all brain as controls
#2b. select normals based on the top primary site
  #note there are subtypes of which brain sites are there
  #instead of all brain sites we can select the part with highest correlation
    #e.g. cortex, medulla etc...
#2c. change the graph to plot more specific sites mentioned in 2b. 

#rm(p,normal_median_cor,phenoDF,phenoDF_case,reference_tissue_rank,top_refs) before selecting another set.
```
***

##Run Differential Expressions##  

Variables needed:  

* case_id : samples IDs of case tissues in a character vector
* control_id : samples IDs of control tissues in a character vector
* dz_expr : dataframe that contains both case_id and control_id in its column names, 
* outputFolder : folder to place output files

***

Read csv with gene information and read Diff_Exp.R script.  
This will output 3 files: "computedEmpGenes.csv", "DE_genes.csv", and  "highExpGenes.csv".  
```{r DE2, message=FALSE, warning=FALSE}
setwd(base.folder)

DE.start <- Sys.time()

source(paste0(CodeFolder,'Diff_Exp.R'))

DE.end <- Sys.time()
DE.time <- DE.end - DE.start
DE.time
```
***

##Disease Signature##  
***  

Get the disease signature.
```{r dz_signature}
setwd(base.folder)
dz_signature <- res %>% filter(padj < padjusted, abs(log2FoldChange)>log2fchange)
#filter out res df to get dz sigs
#Term res refers to the results table that is generated from the Diff_Exp. R script.
dim(dz_signature)
head(dz_signature)
```
***

Combine the res table with the Ensembl table to generate a differential expression results table with gene information.
```{r res_geneinfo}
setwd(base.folder)
res_geneinfo <- left_join(res, merged_gene_info, by=c('identifier'='ensembl'))


write.csv(res_geneinfo,file=paste0(outputFolder,'res_geneinfo.csv'))
```
***

Generate table for disease signature
```{r dz_signature2}
setwd(base.folder)
dz_signature <- dz_signature %>% left_join(ensembl_info %>% select(gene,ensembl,chrom,strand),
                                           by=c('identifier'='ensembl'))
dim(dz_signature)
head(dz_signature)


#the column name may differ between different metadata but you need Symbol to join with RGES
dz_signature$Symbol <- toupper(dz_signature$gene)
str(dz_signature$Symbol)


write.csv(dz_signature, paste0(outputFolder, "/dz_signature.csv"),row.names = F)
```
***

##Affected Pathways and Potential Drugs for Reversal##  
***
Find potential drugs that may reverse disease signature.  Takes ~10mins to run following chunk. Following scripts will output "all_lincs_score.csv"" and "sRGES.csv".  
File all_lincs_score.csv has the RGES (reversal gene expression score), which is needed for the gene_enrichment_analysis script later.    
File sRGES.csv is the summarized RGES.
```{r sRGES}
setwd(base.folder)
sRGES.start <- Sys.time()
# source(paste0(CodeFolder,'drugs_core_functions.R'))
#functions needed to run RGES
source(paste0(CodeFolder,'runRGES_dz_arrangeMax_compiler.R'))

sRGES.end <- Sys.time()
sRGES.time <- sRGES.end - sRGES.start
sRGES.time
```
***

See which pathways are affected by running following code. This results the up-regulated pathways as "dz_up_sig_genes_enriched.csv" and the down-regulated pathways as "dz_dn_sig_genes_enriched.csv". 
```{r GEA, message=FALSE, warning=FALSE}
#optional - duration: approximately 7 seconds
setwd(base.folder)
GEA.time.start <- Sys.time()

geneEnrich(dz_signature)

GEA.time.stop <- Sys.time()
GEA.time <- GEA.time.stop - GEA.time.start
GEA.time
```
***

Ouput the "lincs_reverse_expression.pdf' containing a heatmap showing drug hits and their effects on mRNA expression.
```{r VisualizeDrugHits, message=FALSE, warning=FALSE}
#optional - duration: approximately 5 seconds
setwd(base.folder)
VDH.time.start <- Sys.time()
source(paste0(CodeFolder,'visualize_drug_hits.R'))
VDH.time.stop <- Sys.time()
VDH.time <- VDH.time.stop - VDH.time.start
VDH.time
```
***

##Drug Enrichment Analysis##
Additional files are needed here, depending on target_type.  
Each of the target_type will create a pdf and a csv file. 
  

***  
```{r EnrichmentAnalysis, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, results='hide'}
#optional - duration: approximately 20-40 minutes, depending on "targets". Note: "ChemCluster" is listed (enabled/disabled) separately.
setwd(base.folder)
enrich.time.start <- Sys.time()

source(paste0(CodeFolder,'core_functions.R'))
targets = c('chembl_targets','mesh','meshes','sea_targets','ChemCluster') # include as many or few as you prefer. 
# targets = c('chembl_targets','mesh','meshes')


enrichFolder <- paste0(outputFolder,'enrichment_analysis/')
if (!dir.exists(enrichFolder)) {
  dir.create(enrichFolder)
}

sRGES = read.csv(paste0(outputFolder,'/sRGES.csv'),stringsAsFactors = F)
load(paste0(dataFolder,"random_gsea_score.RData"))

for (target_type in targets){
  drug_enrichment(sRGES = sRGES, target_type = target_type)
}


enrich.time.stop <- Sys.time()
enrich.time <- enrich.time.stop - enrich.time.start
enrich.time
```
## Find best cell line & Validate with cell line data in silico ##
```{r RankCellLines, eval=TRUE, message=FALSE, warning=FALSE}
#optional - Duration: approximately 20 seconds.
setwd(base.folder)
ranking.time.start  <- Sys.time()

topline <- computeCellLine(case_id = case_id,
                           expSet = dz_expr,
                           LINCS_overlaps = T)

topLineEval(topline = topline)

ranking.time.stop  <- Sys.time()
ranking.time <- ranking.time.stop - ranking.time.start
ranking.time
```
##Platform and packages used in analysis##
```{r sessioninfo}
setwd(base.folder)
writeLines(capture.output(sessionInfo()), paste0(outputFolder,"session_info.txt"))
```
***
##Time Logging##
```{r logtime}
setwd(base.folder)
end.time <- Sys.time()

total.time <- end.time - start.time
total.time

write('x', file = paste0(outputFolder,"time_log.txt"))
fileConn<-file(paste0(outputFolder,"time_log.txt"))
writeLines(c(
  "Time Log (in seconds, minutes, or hours)","",
  "Total Time",total.time,"",
  "Data Load Time", data.load.time,"",
  "control_id time",case.load.time,"",
  "tSNE Time",tsne.time,"",
  "DE Time",DE.time,"",
  "sRGES Time",sRGES.time,"",
  "Enrich Time",enrich.time,"",
  "GEA Time",GEA.time,"",
  "Visualize Hits Time",VDH.time,"",
  "Ranking Time",ranking.time),
  fileConn)
close(fileConn)
```

```

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

